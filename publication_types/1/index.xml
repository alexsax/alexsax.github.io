<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 on Sasha Sax</title>
    <link>https://alexsax.github.io/publication_types/1/</link>
    <description>Recent content in 1 on Sasha Sax</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Sasha Sax</copyright>
    <lastBuildDate>Tue, 24 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://alexsax.github.io/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Learning to Navigate Using Mid-Level Visual Priors</title>
      <link>https://alexsax.github.io/publication/midlevelcorl/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alexsax.github.io/publication/midlevelcorl/</guid>
      <description>See the main website for demos of each policy, including vidos of random rollouts and average reward curves in train and test environments. More results are available, as well as code and an overview video.</description>
    </item>
    
    <item>
      <title>Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies</title>
      <link>https://alexsax.github.io/publication/midlevelbaylearn/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://alexsax.github.io/publication/midlevelbaylearn/</guid>
      <description>See the main website for demos of each policy, including vidos of random rollouts and average reward curves in train and test environments. More results are available, as well as code and an overview video.</description>
    </item>
    
    <item>
      <title>Taskonomy: Disentangling Task Transfer Learning</title>
      <link>https://alexsax.github.io/publication/taskonomy/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://alexsax.github.io/publication/taskonomy/</guid>
      <description>See the main website for live demos of the API and task-specific networks, as well as pretrained models, samples from the transfer networks, and also explanations of the methodology.</description>
    </item>
    
    <item>
      <title>Embodied Real-World Active Perception</title>
      <link>https://alexsax.github.io/publication/gibson/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://alexsax.github.io/publication/gibson/</guid>
      <description>See the main website for interactive tools to explore the dataset as well as an explanation of the methodology.</description>
    </item>
    
  </channel>
</rss>